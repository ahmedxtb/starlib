class(linear$class)
class(hip$clsas)
class(hip$class)
set.seed(1)
?train
model1 <- train(class~., #
			data=known,#
			method='rf',#
			trControl= trainControl(method='cv', #Use cross-validation#
									number=5, #Use 5 folds for cross-validation#
									sampling=none, #Do not use up/down/smote/etc.#
									metric="Accuracy" #Summary metric for performance#
									))
model1 <- train(class~., #
			data=known,#
			method='rf',#
			trControl= trainControl(method='cv', #Use cross-validation#
									number=5, #Use 5 folds for cross-validation#
									#sampling=none, #Do not use up/down/smote/etc.#
									#metric="Accuracy" #Summary metric for performance#
									))
known
known[,keeps_all]
unknown$classPred <- predict(model1, newdata=unknown)
unknown$classPred
model1
names(model)
names(model1)
model1$results
model1$besttune
model1$bestTune
model1$bestTune$1
model1$bestTune[1]
model1$results[which(model1$bestTune[1]),2]
1-0.9646034
unknown.error <- mean(1-(unknown$classPred==unknown$class))
unknown.error
conf_matrix_unknown <- table(unknown$clasPred, unknown$class)
unknown$clasPred
unknown$classPred <- predict(model1, newdata=unknown)
unknown$clasPred
unknown
ctrl <- trainControl(method="cv", classProbs=T)
model1 <- train(class~., data=known,#
			method='rf',#
			ntree = 1500,#
			tuneLength=5,#
			metric='Accuracy',#
			trControl=ctrl)
model1
model1 <- train(class~., data=known,#
			method='rf',#
			#ntree = 1500,#
			#tuneLength=5,#
			metric='Accuracy',#
			trControl=ctrl)
model1
predict(model1, unknown, type='prob')[,1]
dim(predict(model1, unknown, type='prob')[,1])
predict(model1, newdata=unknown)
mean(1-(classPred==unknown$class))
classPred <- predict(model1, newdata=unknown)
length(classPred)
length(unknown$class)
unknown.error <- mean(1-(classPred==unknown$class))#
unknown.error
conf_matrix_unknown <- table(classPred, unknown$class)
conf_matrix_unknown
model1
names(model1)
model1$pred
model1$results
model1$modelInfo
model1
model1 <- train(class~., #
			data=known[,keeps_all],#
			method='rf',#
			metric='Accuracy',#
			trControl= trainControl(method='cv', #Use cross-validation#
									number=5, #Use 5 folds for cross-validation#
									classprobs=T,#
									sampling="none", #Do not use up/down/smote/etc.#
									))
model1 <- train(class~., #
			data=known[,keeps_all],#
			method='rf',#
			metric='Accuracy',#
			trControl= trainControl(method='cv', #Use cross-validation#
									number=5, #Use 5 folds for cross-validation#
									classprobs=T,#
									#sampling="none", #Do not use up/down/smote/etc.#
									))
model1 <- train(class~., #
			data=known[,keeps_all],#
			method='rf',#
			metric='Accuracy',#
			trControl= trainControl(method='cv', #Use cross-validation#
									number=5, #Use 5 folds for cross-validation#
									sampling="none", #Do not use up/down/smote/etc.#
									))
model1 <- train(class~., #
			data=known[,keeps_all],#
			method='rf',#
			metric='Accuracy',#
			trControl= trainControl(method='cv', #Use cross-validation#
									number=5, #Use 5 folds for cross-validation#
									sampling="up", #Do not use up/down/smote/etc.#
									))
model1 <- train(class~., #
			data=known[,keeps_all],#
			method='rf',#
			metric='Accuracy',#
			trControl= trainControl(method='cv', #Use cross-validation#
									number=5, #Use 5 folds for cross-validation#
									sampling="up" #Do not use up/down/smote/etc.#
									))
confusionMatrix(model1)
?confusionMatrix
n
library(DMwR)#
library(ROSE)
ctrl <- trainControl(method='repeatedcv', #
			repeats=5,#
			classProbs=T,#
			sampling='none')
ctrl <- trainControl(method='repeatedcv', #
			repeats=5,#
			classProbs=TRUE,#
			summaryFunction=twoClassSummary,#
			sampling='none')
ctrl <- trainControl(method='repeatedcv', #
			repeats=5,#
			classProbs=TRUE,#
			summaryFunction=twoClassSummary,#
			sampling="down")
ctrl <- trainControl(method = "repeatedcv", repeats = 5, classProbs = TRUE, summaryFunction = twoClassSummary, ## new option here: sampling = "down")
ctrl <- trainControl(method = "repeatedcv", repeats = 5, classProbs = TRUE, summaryFunction = twoClassSummary,  sampling = "down")
ctrl <- trainControl(method='oob', #
			repeats=5,#
			classProbs=TRUE,#
			summaryFunction=twoClassSummary,#
			sampling="down")
ctrl <- trainControl(method='repeatedcv', #
			repeats=5,#
			#classProbs=TRUE,#
			summaryFunction=twoClassSummary,#
			sampling="down")
ctrl <- trainControl(method='repeatedcv', #
			repeats=5,#
			classProbs=TRUE,#
			#summaryFunction=twoClassSummary,#
			sampling="down")
ctrl <- trainControl(method='repeatedcv', #
			repeats=5,#
			classProbs=TRUE,#
			#summaryFunction=twoClassSummary,#
			sampling="Down")
ctrl <- trainControl(method='repeatedcv', #
			repeats=5,#
			classProbs=TRUE,#
			#summaryFunction=twoClassSummary,#
			#sampling="down"#
			)
names(ctrl)
?trainControl
update.packages(caret)
update.packages("caret")
?caret
??caret
?caret
?trainControl
library(caret)
?trainControl
tmp <- installed.packages()#
installedpkgs <- as.vector(tmp[is.na(tmp[,"Priority"]), 1])#
save(installedpkgs, file="installed_old.rda")
load("installed_old.rda")#
tmp <- installed.packages()#
installedpkgs.new <- as.vector(tmp[is.na(tmp[,"Priority"]), 1])#
missing <- setdiff(installedpkgs, installedpkgs.new)#
install.packages(missing)#
update.packages()
source("http://bioconductor.org/biocLite.R") #Link to bioconductor. #
biocLite("biomaRt") #Install biomaRt.#
library(biomaRt) #Load the biomaRt library.
listMarts()#
listDatasets(useMart("ensembl"))#
mart <- useMart(biomart = "ensembl", dataset = "hsapiens_gene_ensembl")
library(biomaRt)
listMarts()
filters = listFilters("ensembl") #Lists filters for restricting output. (See vignette)
filters = listFilters(ensembl) #Lists filters for restricting output. (See vignette)
filters = listFilters(mart) #Lists filters for restricting output. (See vignette)
mart <- useMart(biomart = "ensembl", dataset = "hsapiens_gene_ensembl")#
filters = listFilters(mart) #Lists filters for restricting output. (See vignette)
mart
filters
listAttributes(mart)[1:100,]
my_results <- getBM(attributes = c("hgnc_symbol", "ensembl_gene_id"), mart = mart)
my_results
head(my_results)
sprr4_eid <- my_results[which(hgnc_symbol='SPRR4'),'ensembl_gene_id']
sprr4_eid <- my_results[which(hgnc_symbol='SPRR4'), ]
sprr4_eid <- my_results[which(hgnc_symbol=='SPRR4'), ]
sprr4_eid <- my_results[which(my_results$hgnc_symbol=='SPRR4'), ]
sprr4_eid
sprr4_eid <- my_results[which(my_results$hgnc_symbol=='SPRR4'),'ensembl_gene_id']
sprr4_eid
?getSequence
seq_cDNA <- getSequence(id="SPRR4", type="hgnc_symbol", seqType="cdna", mart = mart)#
show(seq_cDNA)
seq_peptide <- getSequence(id="SPRR4", type="hgnc_symbol", seqType="peptide", mart = mart)#
show(seq_peptide)
?getSequence
seq_peptide <- getSequence(id="SPRR4", type="hgnc_symbol", seqType="peptide", mart = mart)
show(seq_peptide)
seq_peptide
seq_pep <- getSequence(id="SPRR4", type="hgnc_symbol", seqType="peptide", mart = mart)#
show(seq_pep)
?getSequence
my_results <- getBM(attributes = c("hgnc_symbol", "entrezgene"), mart = mart)#
head(my_results) #Shows just the top of the my_results data set. First few rows.
sp44r_entrezID <- my_results[which(my_results$hgnc_symbol=="SPRR4"), ]
sphead(my_results)#
#
sprr4_entrezID <- my_results[which(my_results$hgnc_symbol=="SPRR4"), ]
sprr4_entrezID
sprr4_entrezID <- my_results[which(my_results$hgnc_symbol=="SPRR4"), "entrezgene"]
sprr4_entrezID
sprr4_eID2 <- unlist(mget("SPRR4", org.Hs.egSYMBOL2EG, ifnotfound = NA))
## This code will convert gene symbols back to Entrez ID's.#
biocLite("org.Hs.eg.db")#
library(org.Hs.eg.db)
sprr4_eID2 <- unlist(mget("SPRR4", org.Hs.egSYMBOL2EG, ifnotfound = NA))
sprr4_eID2
library(org.Hs.eg.db)#
#
sprr4_GO <- mget(sprr4_eID2, org.Hs.egGO)#
sprr4_GO
biocLite("GO.db")#
library(GO.db)
GO_BP1 = list(GOID("GO:0018149"), Term("GO:0018149"), Synonym("GO:0018149"), #
  Secondary("GO:0018149"), Definition("GO:0018149"), Ontology("GO:0018149"))
GO_BP1
gocode <- "GO:0018149"#
GO_BP1 = list(GOID(gocode), Term(gocode), Synonym(gocode), #
  Secondary(gocode), Definition(gocode), Ontology(gocode))
GO_BP1
sprr4_GO
gocode <- "GO:0018149"#
GO_BP1 = list(GOID(gocode), Term(gocode), Synonym(gocode), #
  Secondary(gocode), Definition(gocode), Ontology(gocode))#
GO_BP1
gocode <- "GO:0030216"#
GO_BP2 = list(GOID(gocode), Term(gocode), Synonym(gocode), #
  Secondary(gocode), Definition(gocode), Ontology(gocode))#
GO_BP2
gocode <- "GO:0031424"#
GO_BP3 = list(GOID(gocode), Term(gocode), Synonym(gocode), #
  Secondary(gocode), Definition(gocode), Ontology(gocode))  #
GO_BP3
gocode <- "GO:0001533"#
GO_CC1 = list(GOID(gocode), Term(gocode), Synonym(gocode), #
  Secondary(gocode), Definition(gocode), Ontology(gocode))  #
GO_CC1
gocode <- "GO:0005737"#
GO_CC2 = list(GOID(gocode), Term(gocode), Synonym(gocode), #
  Secondary(gocode), Definition(gocode), Ontology(gocode))  #
GO_CC2
gocode <- "GO:0005938"#
GO_CC3 = list(GOID(gocode), Term(gocode), Synonym(gocode), #
  Secondary(gocode), Definition(gocode), Ontology(gocode))    #
GO_CC3
#Biological processes (indicated by 'BP' in GO output.)#
gocode <- "GO:0018149"#
GO_BP1 = list(GOID(gocode), Term(gocode), Synonym(gocode), #
  Secondary(gocode), Definition(gocode), Ontology(gocode))#
GO_BP1#
#
gocode <- "GO:0030216"#
GO_BP2 = list(GOID(gocode), Term(gocode), Synonym(gocode), #
  Secondary(gocode), Definition(gocode), Ontology(gocode))#
GO_BP2 #
gocode <- "GO:0031424"#
GO_BP3 = list(GOID(gocode), Term(gocode), Synonym(gocode), #
  Secondary(gocode), Definition(gocode), Ontology(gocode))  #
GO_BP3
gocode <- "GO:0001533"#
GO_CC1 = list(GOID(gocode), Term(gocode), Synonym(gocode), #
  Secondary(gocode), Definition(gocode), Ontology(gocode))  #
GO_CC1
gocode <- "GO:0005737"#
GO_CC2 = list(GOID(gocode), Term(gocode), Synonym(gocode), #
  Secondary(gocode), Definition(gocode), Ontology(gocode))  #
GO_CC2
gocode <- "GO:0005938"#
GO_CC3 = list(GOID(gocode), Term(gocode), Synonym(gocode), #
  Secondary(gocode), Definition(gocode), Ontology(gocode))    #
GO_CC3
#Molecular function (indicated by 'MF' in the GO output.)#
gocode <- "GO:0005198"#
GO_MF1 = list(GOID(gocode), Term(gocode), Synonym(gocode), #
  Secondary(gocode), Definition(gocode), Ontology(gocode))   #
GO_MF1
brca1_eid <- unlist(mget("BRCA1", org.Hs.egSYMBOL2EG, ifnotfound = NA))
brca1_eid
brca1_GO <- mget(brca1_eid, org.Hs.egGO)
brca1_GO
affy_entrez <- hgu133aENTREZID
biocLite("hgu133a.db")#
library("hgu133a.db")
affy_entrez <- hgu133aENTREZID
affy_entrez
mapped_probes <- mappedkeys(affy_entrez)#
as.list(affy_entrez[mapped_probes[1:5]])
mapped_probes
biocLite("KEGG.db")#
library(KEGG.db)#
library(org.Hs.eg.db)
kegg <- mget(brca1_eid, KEGGEXTID2PATHID, ifnotfound = list(NA))
kegg
KEGGPATHID2NAME$"hsa04120"
## A list of Entrez gene id's.#
EIDs <- c("1", "10", "100", "1000", "5982")#
#
## For each gene, get KEGG identifiers for all known pathways that the gene is involved #
## in. Then inspect the selected pathway names for the second gene. The first pathway#
## identified is involved in caffiene metabolism. You can see an interaction map for #
## this pathway here: #
###
##   http://www.genome.jp/kegg-bin/show_pathway?map00232. #
###
## Notice the CYP1A2 and CYP2A6 genes that are found below (in the 'caffSymbols' object). #
###
## The 'mget' function searches for each of the Entrez ID's in the KEGGEXTID2PATHID list #
## of KEGG entries. If an Entrez ID is not found to have a corresponding KEGG entry, NA #
## is returned. By indexing KEGGEXTID2PATHID by the returned KEGG identifiers, we see the #
## pathways that the corresponding gene is involved in.#
kegg <- mget(EIDs, KEGGEXTID2PATHID, ifnotfound = list(NA))
kegg
KEGGPATHID2NAME$"00232"
KEGGPATHID2NAME$"04120"
ump_EIDs = KEGGPATHID2EXTID$hsa04120#
ump_symbols = mget(ump_EIDs, org.Hs.egSYMBOL, ifnotfound = NA)#
ump_symbols
library(varstar)
?emCalcMix
install("/Users/jennstarling/TAMU/STAT 685 (Astronomy Group)/varstar_package/varstar")#
library(varstar)
library(roxygen2)#
library(devtools)
install("/Users/jennstarling/TAMU/STAT 685 (Astronomy Group)/varstar_package/varstar")#
library(varstar)
?emCalcMix
qcspike_raw <- read.table(file='/Users/jennstarling/TAMU/STAT 646 (Bioinformatics)/Data Sets/Proteomics/qc_spike.csv', header=T, sep=",")
ls()
library(seqinr)
library(Biostrings)
# FUNCTION DEFINITION to generate random permutations of a sequence.#
gen_random_seqs <- function(sq, B) {#
  ## Break input sequence into vector of characters.#
  sq <- strsplit(sq, "")[[1]]#
  n <- length(sq)#
#
  ## Compute sample proportions of each observed letter.#
  sq_tbl <- table(sq)#
  sq_letters <- names(sq_tbl)#
  n_letters <- length(sq_letters)#
  pp <- numeric()#
  for(i in 1:length(sq_letters)) #
    pp[i] <- sq_tbl[i] / n#
  ## Generate B random sequences by sampling with replacement using a multinomial model.#
  sqs <- numeric(B)#
  for(i in 1:B) #
    sqs[i] <- paste(sample(sq_letters, n, rep = TRUE, prob = pp), collapse = "")#
#
  return(sqs)#
}    #
# FUNCTION DEFINITION:  Function for computing a p-value for the alignment of #
# two sequences. Length(seq_1) must be <= Length(seq_2) in the arguments.#
# Type must be 'local' or 'global', in quotes.#
align_p_val <- function(seq_1, seq_2, scoringMat, gapOpen, gapExtend, B, type) {#
  ## Compute alignment score for original pair of sequences.#
  tt_0 <- pairwiseAlignment(seq_1, seq_2, substitutionMatrix = scoringMat, #
    gapOpening = gapOpen, gapExtension = gapExtend, type = type, scoreOnly = TRUE)#
#
  ## Generate B random versions of first sequence.#
  random_seqs <- gen_random_seqs(seq_1, B)#
  ## For each random sequence, re-run the alignment and store the resulting score.#
  tt_B <- numeric(B)#
  for(i in 1:B) #
    tt_B[i] <- pairwiseAlignment(random_seqs[i], seq_2, substitutionMatrix = scoringMat, #
      gapOpening = gapOpen, gapExtension = gapExtend, type = type, scoreOnly = TRUE)#
#
  ## Compute a p-value as the proportion of randomization-based alignment scores that are #
  ## equal to or greater than our original observed score.#
  p_val <- mean(tt_B >= tt_0)#
  return(list("tt_0" = tt_0, "tt_B" = tt_B, "p_val" = p_val))#
}
choosebank("genbank")
H1F0_h <- query(listname = "H1F0", query="SP=homo sapiens AND K=H1F0")
H1F0_m <- query(listname = "H1F0", query="SP=mus musculus AND K=H1F0")
h1f0_h_seqs <- getSequence(H1F0_h)
h1f0_m_seqs <- getSequence(H1F0_m)
h1f0_h_names <- getName(H1F0_h)	#Assign vector of names for each variate sequence.#
h1f0_m_names <- getName(H1F0_m)
h1f0_h_seq1 <- h1f0_h_seqs[[1]]		#Extract first sequence for humans.#
h1f0_m_seq1 <- h1f0_m_seqs[[1]]
sum(h1f0_h_seq1 != h1f0_m_seq1) / length(h1f0_h_seq1)
dotPlot(h1f0_h_seq1, h1f0_m_seq1, col=c("white", "red"), #
  xlab = "H1F0 humans", ylab = "H1F0 mice")
score_mat <- nucleotideSubstitutionMatrix(match = 1, mismatch = -1, baseOnly = TRUE)
gapOpen <- 0#
gapExtend <- -2
seq_1 <- toupper(paste(h1f0_h_seq1, sep="", collapse="")) #Reformat sequence vector to one char string.#
seq_2 <- toupper(paste(h1f0_m_seq1, sep="", collapse="")) #Reformat sequence vector to one char string. #
	#REQUIRES UPPER-CASE LETTER SEQUENCES!
seq_1
seq_2
out <- align_p_val(seq_1, seq_2, score_mat, gapOpen, gapExtend, B = 1000, type='global')
out$p_val
h1f0_sp <- query(listname="h1f0_sp", query="K=h1f0", virtual=TRUE)
h1f0_species <- query(listname="h1f0_species", query="PS h1f0_sp")
h1f0_species_names <- getName(h1f0_species)
h1f0_species_names #Display species names.#
length(h1f0_species_names)
#Obtain all gene sequence variates for humans (h), mice (m) and cows (c).#
h1f0_h <- query(listname="h1f0_sp", query="SP=HOMO SAPIENS AND K=h1f0")
h1f0_m <- query(listname="h1f0_sp", query="SP=MUS MUSCULUS AND K=h1f0")
h1f0_c <- query(listname="h1f0_sp", query="SP=BOS TAURUS AND K=h1f0")
h1f0_h_seq1 <- getSequence(h1f0_h)[[1]]
h1f0_m_seq1 <- getSequence(h1f0_m)[[1]]
h1f0_c_seq1 <- getSequence(h1f0_c)[[1]]
h1f0_h_seq1_name <- getName(h1f0_h)[[1]]
h1f0_m_seq1_name <- getName(h1f0_m)[[1]] #Name for 1st H1F0 sequence for mice.#
h1f0_c_seq1_name <- getName(h1f0_c)[[1]]
biocLite("muscle")
source("http://bioconductor.org/biocLite.R")
biocLite("muscle")
library(muscle)
h <- toupper(paste(h1f0_h_seq1,collapse="")) #Format human seq vector as single all caps char string.#
m <- toupper(paste(h1f0_m_seq1,collapse="")) #Format mouse seq vector as single all caps char string.#
c <- toupper(paste(h1f0_c_seq1,collapse="")) #Format cow seq vector as single all caps char string.#
stringset <- DNAStringSet(c(h,m,c)) #Create a DNA String Set object. Part of 'muscle' package.#
names(stringset) <- c('human','mouse','cow')
h1f0_align <- muscle(stringset)
print(h1f0_align, from = 1, to = 50)
#Z and t-statistic critical value calculator:#
#
#----------------------------------------------------------------#
# Roxy package build comments:#
#' critValCalc(conf,n,p) A critical value function for Z and T distributions.#
#'#
#' This function returns two tables of critical values (one-sided and two-sided)#
#' for the Z (normal) and t (central t) distributions.#
#'#
#' @param conf A vector of confidence levels (1-alpha) to calculate critical values.  #
#' 	Defaults to c(.99, .985, .975, .95, .9)#
#' @param n A sample size for calculating T dist's degrees of freedom.  Defaults to 1000.#
#' @param p The number of parameters being estimated for calculating T dist's degrees of#
#'	freedom.  Defaults to 1.#
#'#
#' @keywords critical values hypothesis testing#
#'#
#' @return Returns a list object x containing the following values.#
#' @return x$n The sample size input by the user.#
#' @return x$p The number of estimated parameters input by the user.#
#' @x$twoSided The table of 2-sided critical values for the Z and T dists.#
#' @x$oneSided The table of 1-sided critical values for the Z and T dists.#
#'#
#' @examples#
#' ## Input specific parameters.#
#' critValCalc(conf=c(.99,.95), n=1000, p=1)#
#' ## Run with default parameters.#
#' critValCalc()#
#'#
#' @author Jennifer Starling#
#'#
#' @export#
#----------------------------------------------------------------#
#
critValCalc = function(conf=c(.99,.98,.975,.95,.9),n=1000,p=1){#
	conf=conf #Takes a user input for a vector of 1+ conf (1-alpha) values to use.#
		#Default value is c(.99, .98, .975, .95, .9)#
	n = n #Sets up n value for df calculation (example, t-dist).#
	p=p #Sets up p parameter for df calculation.#
	a<-1-conf #Set up vector of alpha values.#
	#Calculate 2-sided critical values.#
	z <- qnorm(1-a/2,0,1) #Standard normal Z critical values.#
	t <- qt(1-a/2,n-p)  #Standard values are n-1, for one parameter being estimated.#
	qf(.95, df1=5, df2=2) #
	#Calculate 1-sided critical values.#
	zU<-qnorm(1-a,0,1)#
	tU<-qt(1-a,n-p)#
	x = list()#
	x$n <- n#
	x$p <- p#
	x$twoSided <- cbind(conf,z,t)#
	x$oneSided <- cbind(conf,zU,tU)#
	return(x)#
}
critValCalc(.95,n=1000,p=2)
ChiFCritVals = function(conf=c(.99,.98,.975,.95,.9),n=1000,p=1,n2=1000,p2=1){#
	conf=conf #Takes a user input for a vector of 1+ conf (1-alpha) values to use.#
		#Default value is c(.99, .98, .975, .95, .9)#
	n=n #Sets up n value for df calculation for chi-sq, and df1 for F.#
	p=p #Sets up p parameter for df calculation for chi-sq, and df1 for F.#
	n2=n2 #Sets up n2 value for df calculation for df2 for F.#
	p2=p2 #Sets up p2 parameter for df calculation for df2 for F.#
	a<-1-conf #Set up vector of alpha values.#
	#Calculate 2-sided critical values.#
	c <- qchisq(1-a/2,df=n-p) 			#Chisq dist.#
	f <- qf(1-a/2,df1=n-p,df2=n2-p2)	#F dist.#
	#Calculate 1-sided critical values.#
	cU <- qchisq(1-a,df=n-p) 			#Chisq dist.#
	fU <- qf(1-a,df1=n-p,df2=n2-p2)		#F dist.#
	x = list()#
	x$n <- n#
	x$p <- p#
	x$n2 <- n2#
	x$p2 <- p2#
	x$twoSided <- cbind(conf,c,f)#
	x$oneSided <- cbind(conf,cU,fU)#
	return(x)#
}
ChiFCritVals()
ChiFCritVals = function(conf=c(.99,.98,.975,.95,.9),n=1000,p=1,n2=1000,p2=1){#
	conf=conf #Takes a user input for a vector of 1+ conf (1-alpha) values to use.#
		#Default value is c(.99, .98, .975, .95, .9)#
	n=n #Sets up n value for df calculation for chi-sq, and df1 for F.#
	p=p #Sets up p parameter for df calculation for chi-sq, and df1 for F.#
	n2=n2 #Sets up n2 value for df calculation for df2 for F.#
	p2=p2 #Sets up p2 parameter for df calculation for df2 for F.#
	a<-1-conf #Set up vector of alpha values.#
	#Calculate 2-sided critical values.#
	c <- qchisq(1-a/2,df=n-p-1) 			#Chisq dist.#
	f <- qf(1-a/2,df1=n-p,df2=n2-p2)	#F dist.#
	#Calculate 1-sided critical values.#
	cU <- qchisq(1-a,df=n-p-1) 			#Chisq dist.#
	fU <- qf(1-a,df1=n-p,df2=n2-p2)		#F dist.#
	x = list()#
	x$n <- n#
	x$p <- p#
	x$n2 <- n2#
	x$p2 <- p2#
	x$twoSided <- cbind(conf,c,f)#
	x$oneSided <- cbind(conf,cU,fU)#
	return(x)#
}
ChiFCritVals()
#Chisq & F-statistic critical value calculator:#
#
#----------------------------------------------------------------#
# Roxy package build comments:#
#' ChiFCritVal(conf,n,p) A critical value function for Z and T distributions.#
#'#
#' This function returns two tables of critical values (one-sided and two-sided)#
#' for the Z (normal) and t (central t) distributions.#
#'#
#' @param conf A vector of confidence levels (1-alpha) to calculate critical values.  #
#' 	Defaults to c(.99, .985, .975, .95, .9)#
#' @param n A sample size for calculating T dist's degrees of freedom.  Defaults to 1000.#
#' @param p The number of parameters being estimated for calculating T dist's degrees of#
#'	freedom.  Defaults to 1.#
#'#
#' @keywords critical values hypothesis testing#
#'#
#' @return Returns a list object x containing the following values.#
#' @return x$n The sample size input by the user.#
#' @return x$p The number of estimated parameters input by the user.#
#' @x$twoSided The table of 2-sided critical values for the Z and T dists.#
#' @x$oneSided The table of 1-sided critical values for the Z and T dists.#
#'#
#' @examples#
#' ## Input specific parameters.#
#' critValCalc(conf=c(.99,.95), n=1000, p=1)#
#' ## Run with default parameters.#
#' critValCalc()#
#'#
#' @author Jennifer Starling#
#'#
#' @export#
#----------------------------------------------------------------#
#
ChiFCritVal = function(conf=c(.99,.98,.975,.95,.9),n=1000,p=1,n2=1000,p2=1){#
	conf=conf #Takes a user input for a vector of 1+ conf (1-alpha) values to use.#
		#Default value is c(.99, .98, .975, .95, .9)#
	n=n #Sets up n value for df calculation for chi-sq, and df1 for F.#
	p=p #Sets up p parameter for df calculation for chi-sq, and df1 for F.#
	n2=n2 #Sets up n2 value for df calculation for df2 for F.#
	p2=p2 #Sets up p2 parameter for df calculation for df2 for F.#
	a<-1-conf #Set up vector of alpha values.#
	#Calculate 2-sided critical values. (Both tail probabilities)#
	c <- qchisq(1-a/2,df=n-p-1) 			#Chisq dist.#
	f <- qf(1-a/2,df1=n-p-1,df2=n2-p2-1)	#F dist.#
	#Calculate 1-sided critical values. (Right tail probabilities)#
	cU <- qchisq(1-a,df=n-p-1) 				#Chisq dist.#
	fU <- qf(1-a,df1=n-p-1,df2=n2-p2-1)		#F dist.#
	x = list()#
	x$n <- n#
	x$p <- p#
	x$n2 <- n2#
	x$p2 <- p2#
	x$twoSided <- cbind(conf,c,f)#
	x$oneSided <- cbind(conf,cU,fU)#
	return(x)#
}
ChiFCritVal
ChiFCritVal()
#Chisq & F-statistic critical value calculator:#
#
#----------------------------------------------------------------#
# Roxy package build comments:#
#' ChiFCritVal(conf,n,p) A critical value function for Z and T distributions.#
#'#
#' This function returns two tables of critical values (one-sided and two-sided)#
#' for the chi-squared and F (central) distributions.#
#'#
#' @param conf A vector of confidence levels (1-alpha) to calculate critical values.  #
#' 	Defaults to c(.99, .985, .975, .95, .9)#
#' @param n A sample size for calculating degrees of freedom (df1 for F).  Defaults to 1000.#
#' @param p The number of parameters being estimated for degrees of freedom (df1 for F).  Defaults to 1.#
#' @param n2 A sample size for calculating degrees of freedom (df2 for F).  Defaults to 1000.#
#' @param p2 The number of parameters being estimated for degrees of freedom (df2 for F).  Defaults to 1.#
#'#
#' @keywords critical values hypothesis testing#
#'#
#' @return Returns a list object x containing the following values.#
#' @return x$n The sample size input by the user.#
#' @return x$p The number of estimated parameters input by the user.#
#' @return x$n2 The second sample size input by the user.#
#' @return x$p2 The second number of estimated parameters input by the user.#
#' @x$twoSided The table of 2-sided critical values for the chi-squred and F dists..#
#' @x$oneSided The table of 1-sided critical values (right tail) for the chi-squred and F dists.#
#'#
#' @examples#
#' ## Input specific parameters.#
#' ChiFCritVal(conf=c(.99,.95), n=1000, p=1)#
#' ## Run with default parameters.#
#' ChiFCritVal()#
#'#
#' @author Jennifer Starling#
#'#
#' @export#
#----------------------------------------------------------------#
#
ChiFCritVal = function(conf=c(.99,.98,.975,.95,.9),n=1000,p=1,n2=1000,p2=1){#
	conf=conf #Takes a user input for a vector of 1+ conf (1-alpha) values to use.#
		#Default value is c(.99, .98, .975, .95, .9)#
	n=n #Sets up n value for df calculation for chi-sq, and df1 for F.#
	p=p #Sets up p parameter for df calculation for chi-sq, and df1 for F.#
	n2=n2 #Sets up n2 value for df calculation for df2 for F.#
	p2=p2 #Sets up p2 parameter for df calculation for df2 for F.#
	a<-1-conf #Set up vector of alpha values.#
	#Calculate 2-sided critical values. (Both tail probabilities)#
	c <- qchisq(1-a/2,df=n-p-1) 			#Chisq dist.#
	f <- qf(1-a/2,df1=n-p-1,df2=n2-p2-1)	#F dist.#
	#Calculate 1-sided critical values. (Right tail probabilities)#
	cU <- qchisq(1-a,df=n-p-1) 				#Chisq dist.#
	fU <- qf(1-a,df1=n-p-1,df2=n2-p2-1)		#F dist.#
	x = list()#
	x$n <- n#
	x$p <- p#
	x$n2 <- n2#
	x$p2 <- p2#
	x$twoSided <- cbind(conf,c,f)#
	x$oneSided <- cbind(conf,cU,fU)#
	return(x)#
}
ChiFCritVal()
library(devtools)
devtools::create("/Users/jennstarling/TAMU/starlib")
A <- matrix(c(2,-1,-1,2),nrow=2,byrow=T)
A
eigen(A)
v <- c(1,1)
sqrt(2)
1/sqrt(2)
?rref
install('pracma')
library(pracma)
rref(A)
qr.R(A)
library(Matrix)
rankMatrix(A)
x <- rexp(10)#
xmin <- min(x)
x
xmin
temp <- rep(0,10000)#
for (i in 1:10000) temp[i] <- min(rexp(10))#
#
par(mfrow=c(1,2))#
hist(temp,freq=F)#
hist(temp,freq=F,nclass=40)
par(mfrow=c(1,2))#
hist(temp,freq=F)#
hist(temp,freq=F,nclass=40)#
#
#Looks like the min has exponential distribution, based on graph.#
x <- seq(0,1,length=1001)#
lines(x,10*exp(-10*x))
par(mfrow=c(1,2))#
hist(temp,freq=F)#
hist(temp,freq=F,nclass=40)#
#
#Looks like the min has exponential distribution, based on graph.#
x <- seq(0,1,length=1001)#
lines(x,10*exp(-10*x),col='blue',lwd=2)
x <- rexp(n=1000,rate=1)#
y <- rexp(n=1000,rate=1)
z <- x+y
hist(z,freq=F)
hist(z,freq=F,nclass=40)
hist(z,freq=F,nclass=40)#
lines(x,x*exp(-x),col='blue',lwd=2)
x
z <- rexp(1000) + rexp(1000)
z
hist(z,freq=F,nclass=40)#
lines(x,x*exp(-x),col='blue',lwd=2)
par(mfrow=c(1,2))#
hist(temp,freq=F)#
hist(temp,freq=F,nclass=40)#
#
#Looks like the min has exponential distribution, based on graph.#
x <- seq(0,1,length=1001)#
lines(x,10*exp(-10*x),col='blue',lwd=2)
temp <- rep(0,1000)#
for (i in 1:10000) temp[i] <- rexp(1) + rexp(1)
z <- rep(0,1000)#
for (i in 1:10000) z[i] <- rexp(1) + rexp(1)#
#
hist(z,freq=F,nclass=40)#
lines(x,x*exp(-x),col='blue',lwd=2)
hist(z,freq=F,nclass=40)#
#
x <- seq(0,10,length=1001*10)#
lines(x,x*exp(-x),col='blue',lwd=2)
library(devtools)
setwd('/Users/jennstarling/UTAustin/starlib')
